#### 图片数据爬取之ImagesPipeline

**基于scrapy爬取字符串类型的数据和爬取图片类型的数据区别？**
  * 字符串：只需要基于xpath进行解析且提交管道进行持久化存储
  * 图片：xpath解析出图片src的属性值。单独的对图片地址发起请求获取图片二进制类型的数据

**ImagesPipeline:**
  * 只需要将img的src的属性值进行解析，提交到管道，管道就会对图片的src进行请求发送获取图片的二进制数据

* 需求：爬取站长素材中的高清图片
* 使用流程：
  1. 数据解析（图片的地址）
  2. 将存储图片地址的item提交到制定的管道类
  3. 在管道文件中自定制一个基于ImagesPipeLine的一个管道类
    * get_ media_request
    * file_path
    * item completed
  4. 在配置文件中：
    * 指定图片存储的目录：IMAGES_STORE = ‘./imgs bobo'
    * 指定开启的管道：自定制的管道类

#### 案例：获得站长素材的高清图片

```
主程序
import scrapy
from imgsPro.items import ImgsproItem


class ImgSpider(scrapy.Spider):
    name = 'img'
    # allowed_domains = ['www.xxx.com']
    start_urls = ['https://sc.chinaz.com/tupian/']

    def parse(self, response):
        img_list = response.xpath('//*[@id="container"]/div')
        for img in img_list:
            item = ImgsproItem()

            # 注意懒加载，要使用伪属性
            src1 = img.xpath('./div/a/img/@src2').extract_first()
            src = 'https:' + src1
            item['src'] = src

            yield item
```

```
items.py

import scrapy
class ImgsproItem(scrapy.Item):
    src = scrapy.Field()

```
```
pipelines.py

import scrapy
from itemadapter import ItemAdapter
from scrapy.pipelines.images import ImagesPipeline

class imgsPileline(ImagesPipeline):

    # 根据图片地址进行图片数据请求
    def get_media_requests(self, item, info):
        yield scrapy.Request(item['src'])

    # 指定图片存储的路径
    def file_path(self, request, response=None, info=None, *, item=None):
        imgName = request.url.split('/')[-1]
        return imgName

    # 返回给下一个即将被执行的item
    def item_completed(self, results, item, info):
        return item
```
```
pipleline.py

USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.55 Safari/537.36'

# Obey robots.txt rules
ROBOTSTXT_OBEY = False
LOG_LEVEL = 'ERROR'

# 指定文件存储的目录
IMAGES_STORE = './imgsss'

ITEM_PIPELINES = {
   'imgsPro.pipelines.imgsPileline': 300,
}
```
> 如果执行之后不报错也无存储文件，需要安装pillow库
