#### scrapy框架的基本使用
1. 环境的安装：
   * mac or linux: pip install scrapy
   * 测试：在终端里录入scrapy指令，没有报错即表示安装成功！
2. 创建一个工程：scrapy startproject xxxPro
3. cd xxxPro
4. 在spiders子目录中创建一个爬虫文件
   * scrapy genspider spiderName www.xxt.com
5. 执行工程：
   * scrapy crawl spiderName
6. scrapy数据解析，案例如下
7. scrapy持久化存储
  * 基于终端指令
    * 要求：只可以将parse方法中的返回值存储到本地的文本文件中
    * 注意：持久化存储对应的文本文件的类型只能是：'json', 'jsonlines', 'jl', 'csv', 'xml', 'marshal', 'pickle'
    * 指令：scrapy crawl XX -o filePath
    * 好处：简洁高效便捷
    * 缺点：局限性比较强（数据智能存储到指定后缀的文本文件中）

  * 基于管道
    * 编码流程
      1. 数据解析
      2. 在item类中定义相关的属性
      3. 将解析的数据封装存储到item类型的对象
      4. 将item类型的对象提交给管道进行持久化存储的操作
      5. 在管道类的process_item中要将其接收到的item对象中存储的数据进行持久化存储
      6. 在配置文件中开启管道

#### scrapy数据解析案例
```
import scrapy


class QiushibkSpider(scrapy.Spider):
    name = 'qiushibk'
    # allowed_domains = ['https://www.qiushibaike.com/article/124996947']
    start_urls = ['https://www.qiushibaike.com/text/']

    def parse(self, response):
         div_list = response.xpath('//div[@class="col1 old-style-col1"]/div')
         for div in div_list:
         
             # xpath返回的是列表，但是列表元素一定是Selector类型的对象
             # extract()可以将selector对象中data参数存储的字符串提取出来
             # 方式1：author = div.xpath('./div[1]/a[2]/h2/text()').extract()
             # 方式2：将列表中第0个元素实行extract操作
             author = div.xpath('./div[1]/a[2]/h2/text()').extract_first()
             
             # 要获取span下面的所有内容，但是span下还有其他标签，此时需要使用'//'2个'/'
             # 列表调用了extract()之后，则表示将列表中每一个selector对象中data所对应的字符串中提取出来
             content = div.xpath('./a[1]/div/span//text()').extract()
             content =''.join(content) # 提取文本内容
             
             print(author, content)
             break

```

#### scrapy持久化存储：基于终端指令
```
import scrapy


class QiushibkSpider(scrapy.Spider):
    name = 'qiushibk'
    # allowed_domains = ['https://www.qiushibaike.com/article/124996947']
    start_urls = ['https://www.qiushibaike.com/text/']

    def parse(self, response):
         div_list = response.xpath('//div[@class="col1 old-style-col1"]/div')
         all_data = []  # 存储所有解析到的数据
         for div in div_list:
             # xpath返回的是列表，但是列表元素一定是Selector类型的对象
             # extract()可以将selector对象中data参数存储的字符串提取出来
             # 方式1：author = div.xpath('./div[1]/a[2]/h2/text()').extract()
             # 方式2：将列表中第0个元素实行extract操作
             author = div.xpath('./div[1]/a[2]/h2/text()').extract_first()

             # 要获取span下面的所有内容，但是span下还有其他标签，此时需要使用'//'2个'/'
             # 列表调用了extract()之后，则表示将列表中每一个selector对象中data所对应的字符串中提取出来
             content = div.xpath('./a[1]/div/span//text()').extract()
             content =''.join(content) # 提取文本内容

             dic = {
                 'author': author,
                 'content': content
             }
             all_data.append(dic)

         return all_data

```

#### scrapy持久化存储：基于管道
```

```
