#### scrapy框架的基本使用
1. 环境的安装：
   * mac or linux: pip install scrapy
   * 测试：在终端里录入scrapy指令，没有报错即表示安装成功！
2. 创建一个工程：scrapy startproject xxxPro
3. cd xxxPro
4. 在spiders子目录中创建一个爬虫文件
   * scrapy genspider spiderName www.xxt.com
5. 执行工程：
   * scrapy crawl spiderName

```
import scrapy


class QiushibkSpider(scrapy.Spider):
    name = 'qiushibk'
    # allowed_domains = ['https://www.qiushibaike.com/article/124996947']
    start_urls = ['https://www.qiushibaike.com/text/']

    def parse(self, response):
         div_list = response.xpath('//div[@class="col1 old-style-col1"]/div')
         for div in div_list:
         
             # xpath返回的是列表，但是列表元素一定是Selector类型的对象
             # extract()可以将selector对象中data参数存储的字符串提取出来
             # 方式1：author = div.xpath('./div[1]/a[2]/h2/text()').extract()
             # 方式2：将列表中第0个元素实行extract操作
             author = div.xpath('./div[1]/a[2]/h2/text()').extract_first()
             
             # 要获取span下面的所有内容，但是span下还有其他标签，此时需要使用'//'2个'/'
             # 列表调用了extract()之后，则表示将列表中每一个selector对象中data所对应的字符串中提取出来
             content = div.xpath('./a[1]/div/span//text()').extract()
             content =''.join(content) # 提取文本内容
             
             print(author, content)
             break

```
