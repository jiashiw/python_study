#### 基于Spider的全站数据爬取
就是将网站中某板块下的全部页码对应的页面数据进行爬取

> 需求：爬取'https://www.ivsky.com/tupian/'中的照片的名称

实现方式：
  * 将所有页面的url添加到start_urls列表（不推荐）
  * 自行手动进行请求发送（推荐）
    * 手动请求发送：
      * yield scrapy .Request (url,callback):cal1back专门用做于数据解析

```
import scrapy


class PictureSpider(scrapy.Spider):
    name = 'picture'
    # allowed_domains = ['https://www.ivsky.com/tupian/']
    start_urls = ['https://www.ivsky.com/tupian/']

    # 生成一个通用的url模版(不可变)
    url = 'https://www.ivsky.com/tupian/index_%d.html'
    page_num = 2

    def parse(self, response):
        li_list = response.xpath('/html/body/div[3]/div[2]/ul/li')
        for li in li_list:
            img_name = li.xpath('./div/a/@title').extract_first()
            print(img_name)

        if self.page_num <= 11:
            new_url = format(self.url%self.page_num)
            print(self.page_num)
            # 手动请求发送:callback回调函数专门用作于数据解析
            yield scrapy.Request(url=new_url, callback=self.parse)
            self.page_num += 1
```
